{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ecea1",
   "metadata": {},
   "source": [
    "# NLP - Lab 03\n",
    "\n",
    "### Let's beat the results we obtained with naive Bayes using the FastText library\n",
    "\n",
    "---\n",
    "\n",
    "Authors :\n",
    "\n",
    "eliott.bouhana\\\n",
    "victor.simonin\\\n",
    "alexandre.lemonnier\\\n",
    "sarah.gutierez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d3752c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "951ef258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/leme/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea2f62",
   "metadata": {},
   "source": [
    "### How many splits does the dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38dff7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test', 'unsupervised']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "\n",
    "get_dataset_split_names(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2793054",
   "metadata": {},
   "source": [
    "The dataset is composed of 3 splits: `train`, `test` and `unsupervised`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8e2f9",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "## FastText setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af7a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values in train dataset:  25000\n",
      "Number of negative (0) and positive (1) sentences in train supervised split:\n",
      "0    12500\n",
      "1    12500\n",
      "Name: label, dtype: int64\n",
      "--------------------------------\n",
      "Number of values in test dataset:  25000\n",
      "Number of negative (0) and positive (1) sentences in test supervised split:\n",
      "0    12500\n",
      "1    12500\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "\n",
    "train = dataset[\"train\"].to_pandas()\n",
    "test = dataset[\"test\"].to_pandas()\n",
    "\n",
    "print(\"Number of values in train dataset: \", len(train))\n",
    "print(\"Number of negative (0) and positive (1) sentences in train supervised split:\\n{0}\".format(train['label'].value_counts()))\n",
    "print(\"--------------------------------\")\n",
    "print(\"Number of values in test dataset: \", len(test))\n",
    "print(\"Number of negative (0) and positive (1) sentences in test supervised split:\\n{0}\".format(test['label'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc7bcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681a692",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50ff1e",
   "metadata": {},
   "source": [
    "Before training, we remove the punctuation in our text samples and lowercase them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c85bc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rented i am curiousyellow from my video stor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am curious yellow is a risible and pretentio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this film was probably inspired by godards mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh brotherafter hearing about this ridiculous ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i rented i am curiousyellow from my video stor...      0\n",
       "1  i am curious yellow is a risible and pretentio...      0\n",
       "2  if only to avoid making this type of film in t...      0\n",
       "3  this film was probably inspired by godards mas...      0\n",
       "4  oh brotherafter hearing about this ridiculous ...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from typing import List\n",
    "\n",
    "def preprocessor(x_list: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocessing function to lowercase and remove punctuation of a list of string.\n",
    "    \n",
    "    Args:\n",
    "        x_list: List of strings\n",
    "    \n",
    "    Returns:\n",
    "        List of preprocessed strings.\n",
    "    \"\"\"\n",
    "    return [x.lower().translate(str.maketrans(\"\", \"\", punctuation)) for x in x_list]\n",
    "\n",
    "train['text'] = preprocessor(train['text'])\n",
    "test['text'] = preprocessor(test['text'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25561b7e",
   "metadata": {},
   "source": [
    "### Shuffling\n",
    "\n",
    "To avoid having a strong model bias toward negative, we shuffle our data before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8948d0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the third entry of the phantasm series mike...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i only watched the first 30 minutes of this an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now this is what a family movie should be ther...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show has a great storyline its very belie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a year or so ago i was watching the tv news wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  in the third entry of the phantasm series mike...      0\n",
       "1  i only watched the first 30 minutes of this an...      0\n",
       "2  now this is what a family movie should be ther...      1\n",
       "3  this show has a great storyline its very belie...      1\n",
       "4  a year or so ago i was watching the tv news wh...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_dataset(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Shuffle pandas dataset \n",
    "    \n",
    "    Args:\n",
    "        dataset: pandas Dataframe\n",
    "    \n",
    "    Returns:\n",
    "       The shuffled dataset \n",
    "    \"\"\"\n",
    "    return dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train = shuffle_dataset(train)\n",
    "test = shuffle_dataset(test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d0dce",
   "metadata": {},
   "source": [
    "### Turn the dataset into a dataset compatible with FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7b631",
   "metadata": {},
   "source": [
    "To be able to use `fasttext`, we have to transform each row of our dataset with the following format :\n",
    "\n",
    "`__label__<label> <corresponding_text>`\n",
    "\n",
    "Each line has to be saved in a file which will be used to train with FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95ad62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def dataset_to_fasttext_file(df: pd.DataFrame, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Transform dataframe to a fasttext file with correct format.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas Dataframe\n",
    "        filename: str \n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if df['label'].values.__contains__(0):\n",
    "        df['label'] = df['label'].map({0: \"negative\", 1: \"positive\"})\n",
    "    df = df.astype('str')\n",
    "    with open(filename, 'w') as file:\n",
    "        for index, row in df.iterrows():\n",
    "            fasttext = '__label__' + row['label'] + ' ' + row['text'] + '\\n'\n",
    "            file.write(fasttext)\n",
    "    \n",
    "dataset_to_fasttext_file(train, \"train.fasttext\")\n",
    "dataset_to_fasttext_file(test, \"test.fasttext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eefae3",
   "metadata": {},
   "source": [
    "## FastText classifier\n",
    "\n",
    "Let's train a simple classifier with our formated text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a03921fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  121891\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1060949 lr:  0.000000 avg.loss:  0.406357 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(input=\"train.fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab0b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 25000\n",
      "Accurracy: 0.87624\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.test(\"test.fasttext\")\n",
    "print('Number of samples:', test_prediction[0])\n",
    "print('Accurracy:', test_prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50bdfa",
   "metadata": {},
   "source": [
    "### Hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1cc6a",
   "metadata": {},
   "source": [
    "To find the best parameters for our classifier, we have to split our training data and create a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee955e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the third entry of the phantasm series mike...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i only watched the first 30 minutes of this an...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now this is what a family movie should be ther...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show has a great storyline its very belie...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a year or so ago i was watching the tv news wh...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  in the third entry of the phantasm series mike...  negative\n",
       "1  i only watched the first 30 minutes of this an...  negative\n",
       "2  now this is what a family movie should be ther...  positive\n",
       "3  this show has a great storyline its very belie...  positive\n",
       "4  a year or so ago i was watching the tv news wh...  positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_size = int(len(train) * 0.3)\n",
    "validation = train.iloc[:validation_size:, :] \n",
    "train_hyper = train.iloc[validation_size:, :]\n",
    "\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c33c3",
   "metadata": {},
   "source": [
    "Let's format our validation dataset to a fasttext file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5407a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_fasttext_file(validation, \"validation.fasttext\")\n",
    "dataset_to_fasttext_file(train_hyper, \"train_hyper.fasttext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4602b",
   "metadata": {},
   "source": [
    "Now, let's train and search for the best hyperparameters with the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d2e077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:    7 Best score:  0.898267 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 4M words\n",
      "Number of words:  100524\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1077692 lr:  0.000000 avg.loss:  0.054391 ETA:   0h 0m 0s 922134 lr:  0.071786 avg.loss:  0.475098 ETA:   0h 2m18s 13.3% words/sec/thread:  970074 lr:  0.067106 avg.loss:  0.313050 ETA:   0h 2m 2sh 0m57s% words/sec/thread: 1069316 lr:  0.033094 avg.loss:  0.090018 ETA:   0h 0m54s avg.loss:  0.061926 ETA:   0h 0m17s\n"
     ]
    }
   ],
   "source": [
    "model_hyper = fasttext.train_supervised(input=\"train_hyper.fasttext\", autotuneValidationFile=\"validation.fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a99b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 25000\n",
      "Accurracy: 0.89272\n"
     ]
    }
   ],
   "source": [
    "test_hyper_prediction = model_hyper.test(\"test.fasttext\")\n",
    "print('Number of samples:', test_hyper_prediction[0])\n",
    "print('Accurracy:', test_hyper_prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dda3a",
   "metadata": {},
   "source": [
    "### What is/are the difference(s) between the two models ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386fb93",
   "metadata": {},
   "source": [
    "Let's compare the two accuracy of our models with the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a1d962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model on test dataset accuracy: 0.87624\n",
      "Hyper model on test dataset accuracy: 0.89272\n",
      "Accuracy difference :  0.01647999999999994\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple model on test dataset accuracy:\", test_prediction[1])\n",
    "print(\"Hyper model on test dataset accuracy:\", test_hyper_prediction[1])\n",
    "print(\"Accuracy difference : \", abs(test_prediction[1] - test_hyper_prediction[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a22e43",
   "metadata": {},
   "source": [
    "We can observe that our second model is more accurate on its prediction than our first dataset.\n",
    "The hyperparameters search worked as expected and we got better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6924b00",
   "metadata": {},
   "source": [
    "Now, let's observe the differences between the hyper parameters of our two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfcaed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model learning rate: 0.1\n",
      "Hyper model learning rate: 0.07736590952706915\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple model learning rate:\", model.lr)\n",
    "print(\"Hyper model learning rate:\", model_hyper.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0ce6fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model epoch: 5\n",
      "Hyper model epoch: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple model epoch:\", model.epoch)\n",
    "print(\"Hyper model epoch:\", model_hyper.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63e46691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model loss function: loss_name.softmax\n",
      "Hyper model loss function: loss_name.softmax\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple model loss function:\", model.loss)\n",
    "print(\"Hyper model loss function:\", model_hyper.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "653b66b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model size of word vectors: 100\n",
      "Hyper model size of word vectors: 82\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple model size of word vectors:\", model.dim)\n",
    "print(\"Hyper model size of word vectors:\", model_hyper.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dcf3f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model number of bucket: 0\n",
      "Hyper model number of bucket: 3908064\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple model number of bucket:\", model.bucket)\n",
    "print(\"Hyper model number of bucket:\", model_hyper.bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dfc933",
   "metadata": {},
   "source": [
    "First, we can see that the *learning rate* is more accurate for our second model than the first one. This parameter is really important in the resulting accuracy of our prediction.\n",
    "\n",
    "An other mismatch between the two models is that the *number of epoch* used for both of them are really different, **5** against **100**, meaning that our `model_hyper` has received more training than the simple one.\n",
    "\n",
    "However, the two models use the same *loss function*, another important hyper-parameter in their training.\n",
    "\n",
    "We can finally notice that the *size of word vectors* and the *number of bucket* between the two models are not the same. We can conclude that the values of the `model_hyper` model are better for this two parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da598c9",
   "metadata": {},
   "source": [
    "### Identify prediction failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7874a",
   "metadata": {},
   "source": [
    "Using the tuned model, let's take 2 wrongly classified examples from the test set, and try explaining why the model failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6941fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "__label__positive\n",
      "Got:\n",
      "__label__negative\n",
      "Text:\n",
      "see no evil is the first film from wwe films yes wwe word wrestling entertainment pro wrestling of course being that its a wwe film a wrestler has to star in it the wrestler being glenn jacobs aka kane which is not really important as if you didnt know kane or what wwe stood for you would never know it had anything to do with the wild word of wrestling as the movie has nothing to do with wrestling see no evil is gross out horror film it has some moments were the some people may jump but for the most part its just saying hey look how gross we can get not that there is anything wrong with that jacob goodnight played by kane is sort of a jason type character his mother tortured him as a kid with strict understatement christian beliefs and has warped his mind now hes a big scary chopping killing machine 90 of the movie takes place in an abandon hotel where jacob stalks six teenagers surprised and a handful of adults i could explain why they are in a creepy old hotel but eh who cares despite its lack of originality see no evil is well made for what its supposed to be kane plays an awesome killer and needs little make up to be scary one flaw in the movie is the most annoying possibility people survive i really looking forward to having them being horribly killed but alas does not happen i wish the film didnt have the stigma of wrestling attached to it although like i said the film has nothing to with wrestling people are still closed minded enough not to want to see it because given of course if they are a wrestling hater then again the movie may also make money because wrestling fans will want to see it either way see no evil has top notch effects and little cgi and like i said its quite brutal so like i say its good stuffif you like that sort of thing\n",
      "\n",
      "Expected:\n",
      "__label__negative\n",
      "Got:\n",
      "__label__positive\n",
      "Text:\n",
      "sherlock holmes and the secret weapon starts in switzerland as the worlds foremost detective sherlock holmes basil rathbone outwits the nazis  manages to smuggle a brilliant scientist named dr franz tobel william post jr out of the country  to the relative safety of london but is london as safe as holmes thinks dr tobel has engineered a revolutionary new bomb sight that will change aerial bombardment forever  he has agreed to give it to the british government but those nazis want it just as badly  holmes arch enemy professor moriarty lionel atwill plans on stealing the secret of the bomb sight  selling it to the nazis add the bumbling inspector lestrade denis hoey of scotland yard dr tobels love interest charlotte eberli kaaren verne assassins mysterious scientists  a puzzling coded message  holmes has his work cut out to keep dr tobel alive so he can deliver his bomb sightbr br directed by roy william neill sherlock holmes and the secret weapon was the fourth in a series of fourteen holmes films made between 1939  1946 to feature rathbone  bruce as holmes  watson the script by edward t lowe jr scott darling  edmund l hartmann is based on the short the dancing men by sir arthur conan doyle  isnt the tradition holmes murder mystery as its more of a wartime adventure story to neglect what holmes is all about the solving of complex crimes  mysteries is a big mistake as far as im concerned  the involvement of the nazis  the war as a backdrop to the story feels out of place awkward  just didnt sit too well with me the dialogue isnt great professor moriarty feels almost like an afterthought as if they couldnt come up with a villain for it  as a whole its far less engaging than others in the series however at least its shortbr br director neill does his usual efficient job but you have to cut it a little slack  bear in mind that it was made over 60 years ago it has no real style or imagination  lacks both atmosphere  intrigue as wellbr br technically the film is ok if unspectacular the black and white cinematography is fine although i understand that a computer colourised version is also available the acting is alright bruce  hoey do their usual comic relief turns  rathbones hairstyle in this looks ridiculous  im glad he changed it for later instalmentsbr br sherlock holmes and the secret weapon was a disappointment when compared to some of the other excellent entries in the series there is very little by which i can recommend it  everything that made the others so good seems to be missing here leave this one till last  watch some of the better ones first for die hard fans only\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read test.fasttext to get some test line with fasttext format\n",
    "fasttext_lines = []\n",
    "with open(\"test.fasttext\", \"r\") as file:\n",
    "    for i in range(40):\n",
    "        fasttext_lines.append(file.readline().strip())\n",
    "\n",
    "# Predit with our model the label for the lines read\n",
    "test_predictions = model_hyper.predict(fasttext_lines)\n",
    "\n",
    "# Get two examples from our lines and predictions:\n",
    "# one positive instead of negative, and one negative instead of positive\n",
    "nb_example = 0\n",
    "p_n = 0\n",
    "n_p = 0\n",
    "for i in range(40):\n",
    "    label = \"__label__positive\"\n",
    "    if (fasttext_lines[i].find(\"__label__negative\") != -1):\n",
    "        label = \"__label__negative\"\n",
    "    if test_predictions[0][i][0] == \"__label__positive\" and label == \"__label__negative\" and not p_n:\n",
    "        print(\"Expected:\\n\" + fasttext_lines[i].split(' ')[0])\n",
    "        print(\"Got:\\n\" + test_predictions[0][i][0])\n",
    "        print(\"Text:\\n\" + fasttext_lines[i].split(label)[1].lstrip())\n",
    "        print()\n",
    "        p_n = 1\n",
    "    if test_predictions[0][i][0] == \"__label__negative\" and label == \"__label__positive\" and not n_p:\n",
    "        print(\"Expected:\\n\" + fasttext_lines[i].split(' ')[0])\n",
    "        print(\"Got:\\n\" + test_predictions[0][i][0])\n",
    "        print(\"Text:\\n\" + fasttext_lines[i].split(label)[1].lstrip())\n",
    "        print()\n",
    "        n_p = 1\n",
    "    if p_n and n_p:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68766392",
   "metadata": {},
   "source": [
    "Here we took two examples of mistakes that our model does:\n",
    "- one were the predicted label was positive instead of negative\n",
    "- one were the predicted label was negative instead of positive\n",
    "\n",
    "The main reason of those mistakes is probably because theses inputs contains words that the model probably classify as the other label.\n",
    "\n",
    "Indeed, for the first input, we can find those keywords that can be classified as 'positive':\n",
    "- loves\n",
    "- good\n",
    "- her great fiancé\n",
    "- excellent\n",
    "- brillant\n",
    "- good acting\n",
    "- ...\n",
    "\n",
    "Moreover, we can also notice that this text is pretty long, then, maybe more a text is long, higher is the probability that it will be considered as positive.\n",
    "\n",
    "For the second input, we can find those keywords that can be classified as 'negative':\n",
    "- I don't like\n",
    "- very poor execution\n",
    "- heartbreaking\n",
    "- drama\n",
    "- ...\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
